<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Metadata and dependencies -->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Moody Tunesdays</title>
    <!-- Firebase SDK -->
    <script src="https://www.gstatic.com/firebasejs/8.6.1/firebase-app.js"></script>
    <script src="https://www.gstatic.com/firebasejs/8.6.1/firebase-storage.js"></script>
    <!-- Import face-api.min.js for facial recognition and script.js for custom logic -->
    <script defer src="face-api.min.js"></script>
    <script defer src="script.js"></script>
    <!-- Link to the CSS stylesheet for styling -->
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <!-- Main content and layout -->
    <div id="animatedBackground" class="animated-background"></div> <!-- Background animation -->
    <div id="infoContainer">
        <div id="songInfo">
            <img id="songArtwork" src="" alt="Song Artwork"> <!-- Displays song artwork -->
            <p id="songTitle"></p> <!-- Displays song title -->
            <p id="detectedMood">Detected Mood: None</p> <!-- Shows the detected mood -->
        </div>
        <div id="sensingMessage" style="display: none;">Sensing 3 seconds of emotions...</div> <!-- Hidden message during sensing -->
        <div id="promptMessage" style="display: none;">Please express an emotion!</div> <!-- Hidden prompt message -->
        <div id="countdownMessage"></div> <!-- Displays countdown for next song -->
    </div>
    <div id="videoContainer">
        <video id="video" autoplay muted></video> <!-- Video element for capturing user's face -->
    </div>
</body>
</html>